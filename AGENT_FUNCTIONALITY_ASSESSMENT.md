# ğŸ“Š Agent åŠŸèƒ½å®Œæ•´æ€§è¯„ä¼°

## æ—¥æœŸï¼š2025-10-29

---

## ğŸ” ç°æœ‰ Agent åŠŸèƒ½åˆ†æ

### 1. âœ… **DataCollectionAgent** - æ•°æ®æ”¶é›†ä»£ç†
**åŠŸèƒ½çŠ¶æ€ï¼šå®Œæ•´ âœ“**

- âœ… ä» Yahoo Finance æ”¶é›†è‚¡ç¥¨ä»·æ ¼æ•°æ®
- âœ… ä» NewsAPI æ”¶é›†æ–°é—»æ•°æ®
- âœ… è‡ªåŠ¨å­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆStock, StockData, Newsï¼‰
- âœ… æ•°æ®è´¨é‡éªŒè¯
- âœ… å¼‚æ­¥æ‰§è¡Œ

**è¯„ä¼°**ï¼šåŠŸèƒ½å®Œæ•´ï¼Œæ— éœ€å¢å¼º

---

### 2. âš ï¸ **RiskAnalysisAgent** - é£é™©åˆ†æä»£ç†
**åŠŸèƒ½çŠ¶æ€ï¼šåŸºç¡€åŠŸèƒ½å®Œæ•´ï¼Œéœ€è¦å¢å¼º âš ï¸**

#### ç°æœ‰åŠŸèƒ½ï¼š
- âœ… æ³¢åŠ¨ç‡è®¡ç®—ï¼ˆVolatilityï¼‰
- âœ… Beta ç³»æ•°è®¡ç®—
- âœ… VaRï¼ˆValue at Riskï¼‰è®¡ç®—
- âœ… é£é™©è¯„åˆ†ï¼ˆRisk Score 0-100ï¼‰
- âœ… é£é™©ç­‰çº§è¯„ä¼°ï¼ˆLOW, MEDIUM, HIGH, VERY_HIGHï¼‰

#### ç¼ºå¤±çš„é«˜çº§åŠŸèƒ½ï¼š
- âŒ **æœ€å¤§å›æ’¤ï¼ˆMax Drawdownï¼‰**ï¼šå†å²ä¸Šçš„æœ€å¤§è·Œå¹…
- âŒ **å¤æ™®æ¯”ç‡ï¼ˆSharpe Ratioï¼‰**ï¼šé£é™©è°ƒæ•´åæ”¶ç›Š
- âŒ **å¹´åŒ–æ³¢åŠ¨ç‡**ï¼šå½“å‰åªæœ‰æ—¥æ³¢åŠ¨ç‡
- âŒ **é£é™©å»ºè®®**ï¼šåŸºäºé£é™©æŒ‡æ ‡çš„å…·ä½“å»ºè®®
- âŒ **å‹åŠ›æµ‹è¯•**ï¼šåœ¨æç«¯å¸‚åœºæ¡ä»¶ä¸‹çš„è¡¨ç°

#### å»ºè®®å¢å¼ºï¼š
```python
# éœ€è¦æ·»åŠ çš„æ–¹æ³•
def calculate_max_drawdown(self, stock_data) -> float
def calculate_sharpe_ratio(self, stock_data, risk_free_rate=0.02) -> float
def calculate_annualized_volatility(self, volatility) -> float
def generate_risk_recommendations(self, risk_metrics) -> List[str]
def stress_test_analysis(self, stock_data) -> Dict
```

---

### 3. âš ï¸ **EmotionalAnalysisAgent** - æƒ…ç»ªåˆ†æä»£ç†
**åŠŸèƒ½çŠ¶æ€ï¼šåŸºç¡€åŠŸèƒ½å®Œæ•´ï¼Œéœ€è¦å¢å¼º âš ï¸**

#### ç°æœ‰åŠŸèƒ½ï¼š
- âœ… æ–°é—»æƒ…ç»ªåˆ†æï¼ˆä½¿ç”¨ AI Serviceï¼‰
- âœ… å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ï¼ˆä»·æ ¼ã€æˆäº¤é‡ï¼‰
- âœ… ææƒ§è´ªå©ªæŒ‡æ•°ï¼ˆFear & Greed Indexï¼‰
- âœ… æƒ…ç»ªäº¤æ˜“ä¿¡å·ï¼ˆBUY/SELL/HOLDï¼‰

#### ç¼ºå¤±çš„é«˜çº§åŠŸèƒ½ï¼š
- âŒ **ç¤¾äº¤åª’ä½“æƒ…ç»ª**ï¼šTwitterã€Reddit ç­‰ç¤¾äº¤å¹³å°æƒ…ç»ª
- âŒ **æƒ…ç»ªè¶‹åŠ¿**ï¼šæƒ…ç»ªéšæ—¶é—´çš„å˜åŒ–
- âŒ **æƒ…ç»ªåˆ†ç±»**ï¼šæŒ‰æ–°é—»ç±»åˆ«ï¼ˆè´¢æŠ¥ã€ç›‘ç®¡ã€äº§å“ç­‰ï¼‰åˆ†ç±»æƒ…ç»ª
- âŒ **å…³é”®è¯æå–**ï¼šä»æ–°é—»ä¸­æå–å…³é”®è¯é¢˜
- âŒ **æƒ…ç»ªå¼ºåº¦**ï¼šä¸ä»…æ˜¯æ­£è´Ÿé¢ï¼Œè¿˜è¦æœ‰å¼ºåº¦ï¼ˆæåº¦æ‚²è§‚ vs è½»å¾®æ‚²è§‚ï¼‰

#### å»ºè®®å¢å¼ºï¼š
```python
# éœ€è¦æ·»åŠ çš„æ–¹æ³•
def analyze_sentiment_trend(self, news_data, days=30) -> Dict
def categorize_news_sentiment(self, news_data) -> Dict
def extract_key_topics(self, news_data) -> List[str]
def calculate_sentiment_intensity(self, sentiment_score) -> str
def social_media_sentiment(self, symbol) -> Dict  # å¯é€‰ï¼Œéœ€è¦é¢å¤– API
```

---

### 4. âœ… **AnalysisAgent** - æŠ€æœ¯åˆ†æä»£ç†
**åŠŸèƒ½çŠ¶æ€ï¼šåŠŸèƒ½éå¸¸å®Œæ•´ âœ“âœ“**

#### ç°æœ‰åŠŸèƒ½ï¼š
- âœ… æŠ€æœ¯æŒ‡æ ‡åˆ†æ
  - RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰
  - MACDï¼ˆæŒ‡æ•°å¹³æ»‘å¼‚åŒç§»åŠ¨å¹³å‡çº¿ï¼‰
  - ç§»åŠ¨å¹³å‡çº¿ï¼ˆMA 20, 50, 200ï¼‰
- âœ… å¤šæ—¶é—´æ¡†æ¶åˆ†æ
  - çŸ­æœŸï¼ˆ7å¤©ï¼‰
  - ä¸­æœŸï¼ˆ14å¤©ï¼‰
  - é•¿æœŸï¼ˆ28å¤©ï¼‰
- âœ… è¶‹åŠ¿åˆ†æ
  - è¶‹åŠ¿æ–¹å‘ï¼ˆUP, DOWN, NEUTRALï¼‰
  - è¶‹åŠ¿å¼ºåº¦ï¼ˆWEAK, MODERATE, STRONGï¼‰
  - åŠ¨é‡ï¼ˆPOSITIVE, NEGATIVE, NEUTRALï¼‰
  - æ³¢åŠ¨æ€§ï¼ˆLOW, MEDIUM, HIGHï¼‰
- âœ… åŸºæœ¬é¢åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
  - P/E ä¼°å€¼
  - P/B ä¼°å€¼
  - ä¼°å€¼è¯„ä¼°ï¼ˆUNDERVALUED, FAIR, OVERVALUEDï¼‰
- âœ… äº¤æ˜“ä¿¡å·ç”Ÿæˆ
- âœ… ç½®ä¿¡åº¦è¯„åˆ†

#### å¯ä»¥å¢å¼ºçš„åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰ï¼š
- ğŸ“Œ **å¸ƒæ—å¸¦ï¼ˆBollinger Bandsï¼‰**
- ğŸ“Œ **éšæœºæŒ‡æ ‡ï¼ˆStochastic Oscillatorï¼‰**
- ğŸ“Œ **æˆäº¤é‡åˆ†æï¼ˆVolume Profileï¼‰**
- ğŸ“Œ **æ”¯æ’‘/é˜»åŠ›ä½è¯†åˆ«**
- ğŸ“Œ **å½¢æ€è¯†åˆ«ï¼ˆChart Patternsï¼‰**

**è¯„ä¼°**ï¼šæ ¸å¿ƒåŠŸèƒ½å·²ç»éå¸¸å®Œæ•´ï¼Œå¢å¼ºåŠŸèƒ½å¯ä»¥åç»­æ·»åŠ 

---

### 5. âœ… **ReportGenerateAgent** - æŠ¥å‘Šç”Ÿæˆä»£ç†
**åŠŸèƒ½çŠ¶æ€ï¼šå®Œæ•´ âœ“**

- âœ… æ•´åˆæ‰€æœ‰åˆ†æç»“æœ
- âœ… ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
- âœ… æ ¼å¼åŒ–è¾“å‡º

**è¯„ä¼°**ï¼šåŠŸèƒ½å®Œæ•´ï¼Œæ— éœ€å¢å¼º

---

## ğŸ“ˆ ä¼˜å…ˆçº§è¯„ä¼°

### ğŸ”´ é«˜ä¼˜å…ˆçº§å¢å¼ºï¼ˆå»ºè®®ç«‹å³å®æ–½ï¼‰

#### 1. **RiskAnalysisAgent å¢å¼º**
- âœ… æ·»åŠ æœ€å¤§å›æ’¤è®¡ç®—
- âœ… æ·»åŠ å¹´åŒ–æ³¢åŠ¨ç‡
- âœ… æ·»åŠ é£é™©å»ºè®®ç”Ÿæˆ

**åŸå› **ï¼šç”¨æˆ·é—®"è‚¡ç¥¨é£é™©å¦‚ä½•"æ—¶ï¼Œéœ€è¦æ›´å…¨é¢çš„é£é™©æŒ‡æ ‡

#### 2. **EmotionalAnalysisAgent å¢å¼º**
- âœ… æ·»åŠ æƒ…ç»ªè¶‹åŠ¿åˆ†æ
- âœ… æ·»åŠ æ–°é—»åˆ†ç±»æƒ…ç»ª

**åŸå› **ï¼šç”¨æˆ·éœ€è¦äº†è§£æƒ…ç»ªçš„å˜åŒ–è¶‹åŠ¿ï¼Œè€Œä¸ä»…ä»…æ˜¯å½“å‰çŠ¶æ€

---

### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§å¢å¼ºï¼ˆå»ºè®®åç»­å®æ–½ï¼‰

#### 3. **AnalysisAgent å¢å¼º**
- ğŸ“Œ æ·»åŠ å¸ƒæ—å¸¦
- ğŸ“Œ æ·»åŠ æ”¯æ’‘/é˜»åŠ›ä½

**åŸå› **ï¼šè¿›ä¸€æ­¥æå‡æŠ€æœ¯åˆ†æçš„ä¸“ä¸šæ€§

#### 4. **EmotionalAnalysisAgent å¢å¼º**
- ğŸ“Œ æ·»åŠ ç¤¾äº¤åª’ä½“æƒ…ç»ªï¼ˆéœ€è¦é¢å¤– APIï¼‰

**åŸå› **ï¼šç¤¾äº¤åª’ä½“å¯¹çŸ­æœŸä»·æ ¼å½±å“å¤§ï¼Œä½†éœ€è¦é¢å¤–æˆæœ¬

---

### ğŸŸ¢ ä½ä¼˜å…ˆçº§å¢å¼ºï¼ˆå¯é€‰ï¼‰

#### 5. **AnalysisAgent å¢å¼º**
- ğŸ“Œ å½¢æ€è¯†åˆ«
- ğŸ“Œ æ›´å¤æ‚çš„æŠ€æœ¯æŒ‡æ ‡

**åŸå› **ï¼šç°æœ‰åŠŸèƒ½å·²ç»è¶³å¤Ÿï¼Œè¿™äº›æ˜¯é”¦ä¸Šæ·»èŠ±

---

## ğŸ› ï¸ å»ºè®®çš„å¢å¼ºå®ç°

### 1. RiskAnalysisAgent å¢å¼º

```python
# åœ¨ risk_analysis_agent.py ä¸­æ·»åŠ 

def calculate_max_drawdown(self, stock_data: Dict[str, Any]) -> float:
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    historical_data = stock_data.get("historical_data", [])
    if len(historical_data) < 10:
        return 0.0
    
    prices = [float(day.get("close", 0)) for day in historical_data if day.get("close")]
    if len(prices) < 2:
        return 0.0
    
    # è®¡ç®—ç´¯è®¡æ”¶ç›Š
    returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
    cumulative_returns = [1.0]
    for ret in returns:
        cumulative_returns.append(cumulative_returns[-1] * (1 + ret))
    
    # è®¡ç®—å›æ’¤
    running_max = [cumulative_returns[0]]
    for val in cumulative_returns[1:]:
        running_max.append(max(running_max[-1], val))
    
    drawdowns = [(cumulative_returns[i] - running_max[i]) / running_max[i] 
                 for i in range(len(cumulative_returns))]
    
    max_drawdown = min(drawdowns) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    return round(max_drawdown, 2)

def calculate_annualized_volatility(self, volatility: float, trading_days: int = 252) -> float:
    """è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡"""
    return round(volatility * (trading_days ** 0.5), 2)

def calculate_sharpe_ratio(self, stock_data: Dict[str, Any], risk_free_rate: float = 0.02) -> float:
    """è®¡ç®—å¤æ™®æ¯”ç‡"""
    historical_data = stock_data.get("historical_data", [])
    if len(historical_data) < 10:
        return 0.0
    
    prices = [float(day.get("close", 0)) for day in historical_data if day.get("close")]
    if len(prices) < 2:
        return 0.0
    
    # è®¡ç®—æ”¶ç›Šç‡
    returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
    
    # è®¡ç®—å¹³å‡æ”¶ç›Šå’Œæ ‡å‡†å·®
    avg_return = sum(returns) / len(returns)
    std_return = (sum((r - avg_return) ** 2 for r in returns) / len(returns)) ** 0.5
    
    # å¹´åŒ–
    annual_return = avg_return * 252
    annual_std = std_return * (252 ** 0.5)
    
    # å¤æ™®æ¯”ç‡
    if annual_std == 0:
        return 0.0
    sharpe = (annual_return - risk_free_rate) / annual_std
    return round(sharpe, 2)

def generate_risk_recommendations(self, risk_metrics: Dict[str, Any]) -> List[str]:
    """ç”Ÿæˆé£é™©å»ºè®®"""
    recommendations = []
    
    volatility = risk_metrics.get("volatility", 0)
    max_drawdown = risk_metrics.get("max_drawdown", 0)
    beta = risk_metrics.get("beta", 1.0)
    sharpe = risk_metrics.get("sharpe_ratio", 0)
    
    # åŸºäºæ³¢åŠ¨ç‡çš„å»ºè®®
    if volatility > 30:
        recommendations.append("âš ï¸ é«˜æ³¢åŠ¨æ€§ï¼šå»ºè®®æ§åˆ¶ä»“ä½ï¼Œé¿å…è¿‡åº¦é›†ä¸­")
    
    # åŸºäºæœ€å¤§å›æ’¤çš„å»ºè®®
    if max_drawdown < -30:
        recommendations.append("âš ï¸ å¤§å¹…å›æ’¤é£é™©ï¼šå†å²ä¸Šæ›¾æœ‰è¾ƒå¤§è·Œå¹…ï¼Œéœ€è°¨æ…")
    
    # åŸºäº Beta çš„å»ºè®®
    if beta > 1.5:
        recommendations.append("âš ï¸ é«˜ Betaï¼šè¯¥è‚¡ç¥¨æ³¢åŠ¨æ€§é«˜äºå¸‚åœºå¹³å‡æ°´å¹³ï¼Œé€‚åˆé£é™©åå¥½è¾ƒé«˜çš„æŠ•èµ„è€…")
    elif beta < 0.5:
        recommendations.append("âœ… ä½ Betaï¼šè¯¥è‚¡ç¥¨ç›¸å¯¹ç¨³å®šï¼Œé€‚åˆä¿å®ˆæŠ•èµ„è€…")
    
    # åŸºäºå¤æ™®æ¯”ç‡çš„å»ºè®®
    if sharpe < 0:
        recommendations.append("âš ï¸ è´Ÿå¤æ™®æ¯”ç‡ï¼šé£é™©è°ƒæ•´åæ”¶ç›Šä¸ºè´Ÿï¼Œä¸å»ºè®®æŒæœ‰")
    elif sharpe > 1.0:
        recommendations.append("âœ… è‰¯å¥½çš„é£é™©æ”¶ç›Šæ¯”ï¼šå¤æ™®æ¯”ç‡ > 1.0ï¼Œé£é™©è°ƒæ•´åæ”¶ç›Šè¾ƒå¥½")
    
    if not recommendations:
        recommendations.append("âœ… é£é™©æŒ‡æ ‡åœ¨åˆç†èŒƒå›´å†…")
    
    return recommendations

# ä¿®æ”¹ execute_task æ–¹æ³•
async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œé£é™©åˆ†æä»»åŠ¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    stock_data = task_data.get("stock_data", {})
    market_data = task_data.get("market_data", {})
    
    if not stock_data:
        raise ValueError("Stock data is required for risk analysis")
    
    # è®¡ç®—é£é™©æŒ‡æ ‡
    volatility = self.calculate_volatility(stock_data)
    annualized_volatility = self.calculate_annualized_volatility(volatility)
    beta = self.calculate_beta(stock_data, market_data)
    var = self.calculate_var(stock_data)
    max_drawdown = self.calculate_max_drawdown(stock_data)
    sharpe_ratio = self.calculate_sharpe_ratio(stock_data)
    risk_score = self.calculate_risk_score(volatility, beta, var)
    risk_level = self.assess_risk_level(risk_score)
    
    # ç”Ÿæˆé£é™©å»ºè®®
    risk_metrics = {
        "volatility": annualized_volatility,
        "max_drawdown": max_drawdown,
        "beta": beta,
        "sharpe_ratio": sharpe_ratio
    }
    recommendations = self.generate_risk_recommendations(risk_metrics)
    
    return {
        "symbol": stock_data.get("symbol", ""),
        "volatility": {
            "daily": volatility,
            "annualized": annualized_volatility
        },
        "beta": beta,
        "var": var,
        "max_drawdown": max_drawdown,
        "sharpe_ratio": sharpe_ratio,
        "risk_score": risk_score,
        "risk_level": risk_level,
        "recommendations": recommendations,
        "analysis_timestamp": datetime.utcnow().isoformat()
    }
```

---

### 2. EmotionalAnalysisAgent å¢å¼º

```python
# åœ¨ emotional_analysis_agent.py ä¸­æ·»åŠ 

def analyze_sentiment_trend(self, news_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """åˆ†ææƒ…ç»ªè¶‹åŠ¿"""
    if not news_data:
        return {"trend": "STABLE", "change": 0}
    
    # æŒ‰æ—¥æœŸæ’åº
    sorted_news = sorted(news_data, key=lambda x: x.get("published_at", ""))
    
    # åˆ†æˆä¸¤åŠ
    mid = len(sorted_news) // 2
    first_half = sorted_news[:mid]
    second_half = sorted_news[mid:]
    
    # è®¡ç®—ä¸¤åŠçš„å¹³å‡æƒ…ç»ª
    def avg_sentiment(news_list):
        scores = []
        for news in news_list:
            sentiment = news.get("sentiment", "neutral")
            if sentiment == "positive":
                scores.append(0.8)
            elif sentiment == "negative":
                scores.append(0.2)
            else:
                scores.append(0.5)
        return sum(scores) / len(scores) if scores else 0.5
    
    first_avg = avg_sentiment(first_half)
    second_avg = avg_sentiment(second_half)
    
    # è®¡ç®—å˜åŒ–
    change = second_avg - first_avg
    
    # ç¡®å®šè¶‹åŠ¿
    if change > 0.1:
        trend = "IMPROVING"
    elif change < -0.1:
        trend = "DETERIORATING"
    else:
        trend = "STABLE"
    
    return {
        "trend": trend,
        "change": round(change, 2),
        "first_half_sentiment": round(first_avg, 2),
        "second_half_sentiment": round(second_avg, 2),
        "description": f"æƒ…ç»ª {'æ”¹å–„' if change > 0 else 'æ¶åŒ–' if change < 0 else 'ç¨³å®š'}ï¼Œå˜åŒ– {abs(change):.2f}"
    }

def categorize_news_sentiment(self, news_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """æŒ‰ç±»åˆ«åˆ†ç±»æ–°é—»æƒ…ç»ª"""
    categories = {}
    
    for news in news_data:
        category = news.get("category", "general")
        sentiment = news.get("sentiment", "neutral")
        
        if category not in categories:
            categories[category] = {
                "positive": 0,
                "negative": 0,
                "neutral": 0,
                "total": 0
            }
        
        categories[category][sentiment] += 1
        categories[category]["total"] += 1
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å¹³å‡æƒ…ç»ª
    for category, data in categories.items():
        total = data["total"]
        if total > 0:
            avg_score = (data["positive"] * 0.8 + data["negative"] * 0.2 + data["neutral"] * 0.5) / total
            if avg_score > 0.6:
                data["overall_sentiment"] = "POSITIVE"
            elif avg_score < 0.4:
                data["overall_sentiment"] = "NEGATIVE"
            else:
                data["overall_sentiment"] = "NEUTRAL"
            data["sentiment_score"] = round(avg_score, 2)
    
    return categories

def extract_key_topics(self, news_data: List[Dict[str, Any]]) -> List[str]:
    """ä»æ–°é—»ä¸­æå–å…³é”®è¯é¢˜ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    # ç®€åŒ–ç‰ˆï¼šç»Ÿè®¡é«˜é¢‘è¯
    # å®é™…åº”è¯¥ä½¿ç”¨ NLP æŠ€æœ¯ï¼ˆTF-IDFã€LDA ç­‰ï¼‰
    from collections import Counter
    
    all_words = []
    stop_words = {"the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by"}
    
    for news in news_data:
        title = news.get("title", "")
        words = title.lower().split()
        all_words.extend([w for w in words if w not in stop_words and len(w) > 3])
    
    # ç»Ÿè®¡è¯é¢‘
    word_counts = Counter(all_words)
    top_topics = [word for word, count in word_counts.most_common(5)]
    
    return top_topics

# ä¿®æ”¹ execute_task æ–¹æ³•
async def execute_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
    """æ‰§è¡Œæƒ…ç»ªåˆ†æä»»åŠ¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    news_data = task_data.get("news_data", [])
    stock_data = task_data.get("stock_data", {})
    
    # åŸæœ‰åˆ†æ
    sentiment_analysis = await self.analyze_news_sentiment(news_data)
    market_sentiment = self.analyze_market_sentiment(stock_data)
    fear_greed_index = await self.calculate_fear_greed_index(sentiment_analysis, market_sentiment)
    emotional_signal = self.generate_emotional_signal(fear_greed_index)
    
    # æ–°å¢åˆ†æ
    sentiment_trend = self.analyze_sentiment_trend(news_data)
    categorized_sentiment = self.categorize_news_sentiment(news_data)
    key_topics = self.extract_key_topics(news_data)
    
    return {
        "symbol": stock_data.get("symbol", ""),
        "news_sentiment": sentiment_analysis,
        "market_sentiment": market_sentiment,
        "fear_greed_index": fear_greed_index,
        "emotional_signal": emotional_signal,
        "sentiment_trend": sentiment_trend,  # æ–°å¢
        "categorized_sentiment": categorized_sentiment,  # æ–°å¢
        "key_topics": key_topics,  # æ–°å¢
        "analysis_timestamp": datetime.utcnow().isoformat()
    }
```

---

## ğŸ“Š åŠŸèƒ½å®Œæ•´æ€§æ€»ç»“

| Agent | åŸºç¡€åŠŸèƒ½ | é«˜çº§åŠŸèƒ½ | å»ºè®®å¢å¼º |
|-------|---------|---------|---------|
| **DataCollectionAgent** | âœ… å®Œæ•´ | âœ… å®Œæ•´ | æ— éœ€å¢å¼º |
| **RiskAnalysisAgent** | âœ… å®Œæ•´ | âš ï¸ éœ€è¦å¢å¼º | æœ€å¤§å›æ’¤ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€å¤æ™®æ¯”ç‡ã€é£é™©å»ºè®® |
| **EmotionalAnalysisAgent** | âœ… å®Œæ•´ | âš ï¸ éœ€è¦å¢å¼º | æƒ…ç»ªè¶‹åŠ¿ã€åˆ†ç±»æƒ…ç»ªã€å…³é”®è¯é¢˜ |
| **AnalysisAgent** | âœ… å®Œæ•´ | âœ… éå¸¸å®Œæ•´ | å¯é€‰ï¼šå¸ƒæ—å¸¦ã€æ”¯æ’‘/é˜»åŠ›ä½ |
| **ReportGenerateAgent** | âœ… å®Œæ•´ | âœ… å®Œæ•´ | æ— éœ€å¢å¼º |

---

## ğŸ¯ å®æ–½å»ºè®®

### é˜¶æ®µ 1ï¼šç«‹å³å®æ–½ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
1. âœ… å¢å¼º `RiskAnalysisAgent`
   - æ·»åŠ æœ€å¤§å›æ’¤
   - æ·»åŠ å¹´åŒ–æ³¢åŠ¨ç‡
   - æ·»åŠ å¤æ™®æ¯”ç‡
   - æ·»åŠ é£é™©å»ºè®®

2. âœ… å¢å¼º `EmotionalAnalysisAgent`
   - æ·»åŠ æƒ…ç»ªè¶‹åŠ¿åˆ†æ
   - æ·»åŠ åˆ†ç±»æƒ…ç»ªåˆ†æ

### é˜¶æ®µ 2ï¼šåç»­å®æ–½ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
1. ğŸ“Œ å¢å¼º `AnalysisAgent`
   - æ·»åŠ å¸ƒæ—å¸¦
   - æ·»åŠ æ”¯æ’‘/é˜»åŠ›ä½

2. ğŸ“Œ å¢å¼º `EmotionalAnalysisAgent`
   - æ·»åŠ å…³é”®è¯é¢˜æå–ï¼ˆä½¿ç”¨æ›´å¥½çš„ NLPï¼‰

### é˜¶æ®µ 3ï¼šå¯é€‰å®æ–½ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
1. ğŸ“Œ ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æï¼ˆéœ€è¦é¢å¤– APIï¼‰
2. ğŸ“Œ æ›´å¤æ‚çš„æŠ€æœ¯æŒ‡æ ‡
3. ğŸ“Œ å½¢æ€è¯†åˆ«

---

## ğŸš€ æ€»ä½“è¯„ä¼°

**ç°æœ‰ Agent ç³»ç»Ÿå·²ç»å…·å¤‡äº†éå¸¸æ‰å®çš„åŸºç¡€åŠŸèƒ½**ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
- æ ¸å¿ƒåˆ†æåŠŸèƒ½å®Œæ•´
- ä»£ç ç»“æ„æ¸…æ™°
- æ˜“äºæ‰©å±•
- å·²ç»å¯ä»¥æ»¡è¶³å¤§éƒ¨åˆ†ç”¨æˆ·éœ€æ±‚

âš ï¸ **æ”¹è¿›ç©ºé—´**ï¼š
- é£é™©åˆ†æç¼ºå°‘ä¸€äº›å…³é”®æŒ‡æ ‡ï¼ˆæœ€å¤§å›æ’¤ã€å¤æ™®æ¯”ç‡ï¼‰
- æƒ…ç»ªåˆ†æç¼ºå°‘è¶‹åŠ¿å’Œåˆ†ç±»
- å¯ä»¥æ·»åŠ æ›´å¤šé«˜çº§åŠŸèƒ½

**å»ºè®®**ï¼š
1. **ä¼˜å…ˆå®æ–½é˜¶æ®µ 1** çš„å¢å¼ºï¼ˆæœ€å¤§å›æ’¤ã€å¤æ™®æ¯”ç‡ã€æƒ…ç»ªè¶‹åŠ¿ï¼‰
2. è¿™äº›å¢å¼ºä¼šè®© AI çš„å›ç­”æ›´åŠ ä¸“ä¸šå’Œå…¨é¢
3. åç»­å¯ä»¥æ ¹æ®ç”¨æˆ·åé¦ˆç»§ç»­ä¼˜åŒ–

---

**æ€»çš„æ¥è¯´ï¼Œç°æœ‰ Agent åŠŸèƒ½å·²ç»å¾ˆé½å…¨ï¼Œåªéœ€è¦ä¸€äº›å¢å¼ºå°±èƒ½è¾¾åˆ°ä¸“ä¸šæ°´å¹³ï¼** ğŸŠ




